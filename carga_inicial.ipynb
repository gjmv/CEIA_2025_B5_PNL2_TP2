{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión inicial de vectores en Pinecone\n",
    "\n",
    "### Inicialización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de variables de entorno\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño teórico del embedding: 768. Tamaño real del embedding: 768.\n"
     ]
    }
   ],
   "source": [
    "### EMBEDDINGS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_size = embedding_model._client.get_sentence_embedding_dimension()\n",
    "print(f\"Tamaño teórico del embedding: {embedding_size}. Tamaño real del embedding: {len(embedding_model.embed_query('hola'))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de documentos que estarán disponibles para el chatbot en la base de datos vectorial Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Páginas cargadas: 3\n"
     ]
    }
   ],
   "source": [
    "# Cargar documentos PDF\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents\n",
    "\n",
    "docs_dir = os.getenv(\"DOCS_DIR\") or \"./docs\"\n",
    "docs = read_doc(docs_dir)\n",
    "\n",
    "print(f\"Páginas cargadas: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragmentación de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de fragmentos: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return doc\n",
    "\n",
    "chunks=chunk_data(docs=docs,chunk_size=1000, chunk_overlap=50)\n",
    "print(f\"Cantidad de fragmentos: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga inicial de documentos a Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index ceia-2025-b5-pnl2-tp2 borrado.\n",
      "Index creado con el nombre: ceia-2025-b5-pnl2-tp2.\n"
     ]
    }
   ],
   "source": [
    "## CONNECT WITH PINECONE DATABASE\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in environment variables\") \n",
    "\n",
    "#Connect to Pinecone DB\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "index_name = os.environ.get('PINECONE_INDEX_NAME') or 'ceia-2025-b5-pnl2-tp2'\n",
    "recreate_index = os.environ.get('PINECONE_RECREATE_INDEX') or False\n",
    "\n",
    "if recreate_index and index_name in pc.list_indexes().names():\n",
    "  pc.delete_index(index_name)\n",
    "  print(f\"Index {index_name} borrado.\")\n",
    "\n",
    "# check if index already exists\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=embedding_size, # dimensionality of embeddings\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "        )\n",
    "    print(f\"Index creado con el nombre: {index_name}.\")\n",
    "else:\n",
    "    print(f\"El index con el nombre {index_name} ya estaba creado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted values to ceia-2025-b5-pnl2-tp2 index\n"
     ]
    }
   ],
   "source": [
    "## UPSERT THE VECTORS IN TO THE PINECONE DATABASE\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "namespace = \"documentos\"\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(f\"Upserted values to {index_name} index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de carga inicial con consultas a la base de datos de Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='649fbc02-671a-45dc-ac2b-3561b2bfd00d', metadata={'author': 'Gustavo Viñas', 'creationdate': '2025-11-25T22:05:05-03:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-11-25T22:05:05-03:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'docs\\\\cvRobOtto.pdf', 'total_pages': 3.0}, page_content='Rob Otto \\nIngeniero de Machine Learning & Especialista en IA     Buenos Aires, Argentina \\n(Disponibilidad Remota/Híbrida)         rob.otto@email.ficticio |    \\nlinkedin.com/in/rob.otto.no.me.busquen |            github.com/rob.otto.noexiste.perfil  \\nPerfil Profesional \\nIngeniero de Software especializada en Inteligencia Artificial con más de 4 años de \\nexperiencia en el ciclo de vida completo de modelos de Machine Learning. Experta en el \\ndesarrollo de soluciones de Procesamiento de Lenguaje Natural (NLP) y Visión por \\nComputadora, con un enfoque reciente en la implementación de LLMs (Large Language \\nModels) en entornos productivos. Apasionado por transformar la investigación académica en \\nsoluciones de negocio escalables y eficientes. \\n \\nHabilidades Técnicas \\n• Lenguajes: Python (Experto), SQL, C++, Bash. \\n• Deep Learning & ML: PyTorch, TensorFlow, Scikit-learn, Hugging Face Transformers, \\nKeras, XGBoost.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"in which companies did Rob Otto used to work\"\n",
    "vectorstore.similarity_search(query, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba básica de chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY not found in environment variables\") \n",
    "\n",
    "chat = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided information, Rob Otto has worked in the following companies:\n",
      "\n",
      "1. TechNova Solutions (Fintech) - Senior AI Engineer (Noviembre 2022 – Presente)\n",
      "2. Retail Analytics Corp - Data Scientist (Junio 2020 – Octubre 2022)\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Crear la cadena que procesa los documentos (\"stuff\")\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer based in context:\\n\\n{context}\\n\\Question: {input}\"\"\")\n",
    "combine_docs_chain = create_stuff_documents_chain(chat, prompt)\n",
    "\n",
    "# 2. Crear la cadena de recuperación completa\n",
    "qa_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "# 3. Ejecutar\n",
    "result = qa_chain.invoke({\"input\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, Rob Otto has hands-on experience with the following:\n",
      "\n",
      "1. **Keras**: He is listed as one of the tools he is familiar with under the \"Habilidades Técnicas\" (Technical Skills) section.\n",
      "2. **XGBoost**: Also listed as one of the tools he is familiar with under the \"Habilidades Técnicas\" section.\n",
      "3. **Fine-tuning de LLMs (Llama 3, Mistral)**: He has experience fine-tuning LLMs, specifically mentioning Llama 3 and Mistral, in his project \"LegalSumm AI\" and in his role as a Senior AI Engineer at TechNova Solutions.\n",
      "4. **RAG (Retrieval-Augmented Generation)**: He designed and implemented a RAG system using LangChain and OpenAI API in his role as a Senior AI Engineer at TechNova Solutions.\n",
      "5. **LangChain**: He used LangChain in his project \"LegalSumm AI\" and in his role as a Senior AI Engineer at TechNova Solutions.\n",
      "6. **Prompt Engineering**: Although not explicitly mentioned, his experience with fine-tuning LLMs and designing RAG systems implies familiarity with prompt engineering.\n",
      "7. **Docker**: He deployed a FastAPI API using Docker in his project \"LegalSumm AI\".\n",
      "8. **Kubernetes**: He is familiar with Kubernetes in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\n",
      "9. **MLflow**: He used MLflow in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\n",
      "10. **DVC (Data Version Control)**: He is familiar with DVC in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\n",
      "11. **PostgreSQL**: He is familiar with PostgreSQL, although the specific details are not provided.\n",
      "12. **MongoDB**: He is familiar with MongoDB, although the specific details are not provided.\n",
      "13. **Pinecone (Vector DB)**: He is familiar with Pinecone, although the specific details are not provided.\n",
      "14. **ChromaDB**: He is familiar with ChromaDB, although the specific details are not provided.\n",
      "15. **Álgebra Lineal**: He has a background in linear algebra, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\n",
      "16. **Cálculo Multivariable**: He has a background in multivariable calculus, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\n",
      "17. **Estadística Bayesiana**: He has a background in Bayesian statistics, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\n",
      "\n",
      "These are the hands-on experiences and skills mentioned in the provided information.\n"
     ]
    }
   ],
   "source": [
    "query = \"does Rob Otto have any hands-on experience\"\n",
    "\n",
    "result = qa_chain.invoke({\"input\": query})\n",
    "print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'does Rob Otto have any hands-on experience', 'context': [Document(id='3b94ec57-219c-4338-908d-df473581aec5', metadata={'author': 'Gustavo Viñas', 'creationdate': '2025-11-25T22:05:05-03:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-11-25T22:05:05-03:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'docs\\\\cvRobOtto.pdf', 'total_pages': 3.0}, page_content='Keras, XGBoost. \\n• IA Generativa: Fine-tuning de LLMs (Llama 3, Mistral), RAG (Retrieval-Augmented \\nGeneration), LangChain, Prompt Engineering. \\n• MLOps & Cloud: AWS (SageMaker, Lambda), Azure ML, Docker, Kubernetes, MLflow, \\nDVC (Data Version Control). \\n• Bases de Datos: PostgreSQL, MongoDB, Pinecone (Vector DB), ChromaDB. \\n• Matemáticas: Álgebra Lineal, Cálculo Multivariable, Estadística Bayesiana. \\n \\nExperiencia Laboral \\nSenior AI Engineer | TechNova Solutions (Fintech) \\nNoviembre 2022 – Presente \\nLidero la iniciativa de automatización de atención al cliente utilizando IA Generativa. \\n• Diseñé e implementé un sistema de RAG (Retrieval-Augmented Generation) \\nutilizando LangChain y OpenAI API, reduciendo el tiempo de respuesta de soporte en \\nun 45%. \\n• Desarrollé un pipeline de MLOps en AWS SageMaker para reentrenar \\nautomáticamente modelos de detección de fraude, mejorando la precisión (F1-Score) \\ndel 88% al 94%.'), Document(id='1dd92118-e158-4643-a9c2-0597fa2caf22', metadata={'author': 'Gustavo Viñas', 'creationdate': '2025-11-25T22:05:05-03:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-11-25T22:05:05-03:00', 'page': 1.0, 'page_label': '2', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'docs\\\\cvRobOtto.pdf', 'total_pages': 3.0}, page_content='• Optimicé costos de inferencia mediante la cuantización de modelos (int8) y el uso de \\nONNX Runtime, logrando un ahorro del 30% en costos de nube. \\n• Mentora técnica de 2 ingenieros junior en buenas prácticas de código y despliegue de \\nmodelos. \\nData Scientist | Retail Analytics Corp \\nJunio 2020 – Octubre 2022 \\nEncargado del desarrollo de modelos predictivos para optimización de inventario. \\n• Creé modelos de Time Series (Prophet y LSTM) para predecir la demanda de stock \\nen 500 sucursales, reduciendo el sobre-stock en un 15%. \\n• Implementé un sistema de recomendación híbrido (filtrado colaborativo + basado en \\ncontenido) que aumentó el ticket promedio de compra online en un 12%. \\n• Automaticé la limpieza y preprocesamiento de datos (ETL) utilizando Apache Airflow \\ny SQL, ahorrando 10 horas semanales de trabajo manual al equipo de datos. \\n \\nProyectos Destacados \\nLegalSumm AI (Proyecto Personal) \\n• Desarrollo de una herramienta SaaS para resumir contratos legales complejos.'), Document(id='49208e39-a3d8-4588-9fce-46bf3e796285', metadata={'author': 'Gustavo Viñas', 'creationdate': '2025-11-25T22:05:05-03:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-11-25T22:05:05-03:00', 'page': 1.0, 'page_label': '2', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'docs\\\\cvRobOtto.pdf', 'total_pages': 3.0}, page_content='• Fine-tuning de un modelo Mistral-7B utilizando LoRA (Low-Rank Adaptation) con un \\ndataset legal en español. \\n• Despliegue de la API utilizando FastAPI y Docker en una instancia GPU de bajo costo. \\nSistema de Detección de Defectos (Visión por Computadora) \\n• Entrenamiento de una red YOLOv8 para detectar fallas en líneas de producción \\nmanufacturera en tiempo real. \\n• Integración con cámaras IoT y procesamiento en el borde (Edge Computing) usando \\nNVIDIA Jetson. \\n \\nEducación \\nMáster en Inteligencia Artificial y Ciencia de Datos Universidad de Buenos Aires (UBA) | \\n2019 – 2021 \\n• Tesis: \"Optimización de Transformers para textos médicos en español\" . \\nLicenciatura en Ciencias de la Computación Instituto Tecnológico de Buenos Aires (ITBA) | \\n2015 – 2019'), Document(id='649fbc02-671a-45dc-ac2b-3561b2bfd00d', metadata={'author': 'Gustavo Viñas', 'creationdate': '2025-11-25T22:05:05-03:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-11-25T22:05:05-03:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'docs\\\\cvRobOtto.pdf', 'total_pages': 3.0}, page_content='Rob Otto \\nIngeniero de Machine Learning & Especialista en IA     Buenos Aires, Argentina \\n(Disponibilidad Remota/Híbrida)         rob.otto@email.ficticio |    \\nlinkedin.com/in/rob.otto.no.me.busquen |            github.com/rob.otto.noexiste.perfil  \\nPerfil Profesional \\nIngeniero de Software especializada en Inteligencia Artificial con más de 4 años de \\nexperiencia en el ciclo de vida completo de modelos de Machine Learning. Experta en el \\ndesarrollo de soluciones de Procesamiento de Lenguaje Natural (NLP) y Visión por \\nComputadora, con un enfoque reciente en la implementación de LLMs (Large Language \\nModels) en entornos productivos. Apasionado por transformar la investigación académica en \\nsoluciones de negocio escalables y eficientes. \\n \\nHabilidades Técnicas \\n• Lenguajes: Python (Experto), SQL, C++, Bash. \\n• Deep Learning & ML: PyTorch, TensorFlow, Scikit-learn, Hugging Face Transformers, \\nKeras, XGBoost.')], 'answer': 'Based on the provided information, Rob Otto has hands-on experience with the following:\\n\\n1. **Keras**: He is listed as one of the tools he is familiar with under the \"Habilidades Técnicas\" (Technical Skills) section.\\n2. **XGBoost**: Also listed as one of the tools he is familiar with under the \"Habilidades Técnicas\" section.\\n3. **Fine-tuning de LLMs (Llama 3, Mistral)**: He has experience fine-tuning LLMs, specifically mentioning Llama 3 and Mistral, in his project \"LegalSumm AI\" and in his role as a Senior AI Engineer at TechNova Solutions.\\n4. **RAG (Retrieval-Augmented Generation)**: He designed and implemented a RAG system using LangChain and OpenAI API in his role as a Senior AI Engineer at TechNova Solutions.\\n5. **LangChain**: He used LangChain in his project \"LegalSumm AI\" and in his role as a Senior AI Engineer at TechNova Solutions.\\n6. **Prompt Engineering**: Although not explicitly mentioned, his experience with fine-tuning LLMs and designing RAG systems implies familiarity with prompt engineering.\\n7. **Docker**: He deployed a FastAPI API using Docker in his project \"LegalSumm AI\".\\n8. **Kubernetes**: He is familiar with Kubernetes in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\\n9. **MLflow**: He used MLflow in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\\n10. **DVC (Data Version Control)**: He is familiar with DVC in his role as a Senior AI Engineer at TechNova Solutions, although the specific details are not provided.\\n11. **PostgreSQL**: He is familiar with PostgreSQL, although the specific details are not provided.\\n12. **MongoDB**: He is familiar with MongoDB, although the specific details are not provided.\\n13. **Pinecone (Vector DB)**: He is familiar with Pinecone, although the specific details are not provided.\\n14. **ChromaDB**: He is familiar with ChromaDB, although the specific details are not provided.\\n15. **Álgebra Lineal**: He has a background in linear algebra, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\\n16. **Cálculo Multivariable**: He has a background in multivariable calculus, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\\n17. **Estadística Bayesiana**: He has a background in Bayesian statistics, which is likely a requirement for his role as a Senior AI Engineer and Data Scientist.\\n\\nThese are the hands-on experiences and skills mentioned in the provided information.'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
